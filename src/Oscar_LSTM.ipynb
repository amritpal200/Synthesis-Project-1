{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CODIGO ANTIGUO. TENDRE´QUE ELIMINAR ESTE FICHERO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StXkBL_k-7KF"
      },
      "source": [
        "## Simple Example org LSTMv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmOe2Y7vrdDN"
      },
      "source": [
        "The idea of this approach is that the model has to be able to represent the same log after being transfered into a low dimension. Then, if we train the model with the normal logs (the majority of logs in our dataset) we would have trained the model to represent the normal logs. Therefore, if an anomalous log is presented, the model would work badly, and here is where we can identify the anomaly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qP7KGPQV_LXg"
      },
      "outputs": [],
      "source": [
        "# imports:\n",
        "\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from skipgram import *\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbGvOnVo_SzQ"
      },
      "source": [
        "###Step 1: Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "HZ09UG7d27HS",
        "outputId": "c1f68b97-d568-497e-f893-d693d2a7c59d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL</th>\n",
              "      <th>bytes</th>\n",
              "      <th>referer</th>\n",
              "      <th>user-agent</th>\n",
              "      <th>group</th>\n",
              "      <th>elapsed</th>\n",
              "      <th>IP_oct0</th>\n",
              "      <th>IP_oct1</th>\n",
              "      <th>IP_oct2</th>\n",
              "      <th>IP_oct3</th>\n",
              "      <th>...</th>\n",
              "      <th>minute_cos</th>\n",
              "      <th>petition_-</th>\n",
              "      <th>petition_GET</th>\n",
              "      <th>petition_HEAD</th>\n",
              "      <th>petition_POST</th>\n",
              "      <th>petition_other</th>\n",
              "      <th>status_1</th>\n",
              "      <th>status_2</th>\n",
              "      <th>status_3</th>\n",
              "      <th>status_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/comu/fancybox/jquery.fancybox.css?v=2.1.7 HTT...</td>\n",
              "      <td>-0.597348</td>\n",
              "      <td>https://www.sitgesanytime.com/es/pl415/blog/ll...</td>\n",
              "      <td>Mozilla/5.0 (compatible; AhrefsBot/7.0; +http:...</td>\n",
              "      <td>551</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.427313</td>\n",
              "      <td>-0.342599</td>\n",
              "      <td>-0.744068</td>\n",
              "      <td>1.620095</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/nl/pl383/ontdekken/recensies-en-gastheren/men...</td>\n",
              "      <td>0.418239</td>\n",
              "      <td>-</td>\n",
              "      <td>PhxBot/0.1 (phxbot@protonmail.com)</td>\n",
              "      <td>1675</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>-1.820773</td>\n",
              "      <td>-1.110110</td>\n",
              "      <td>2.453028</td>\n",
              "      <td>-0.878825</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/comu/js/jquery-ui-1.13.1/jquery-ui.min.js HTT...</td>\n",
              "      <td>1.804745</td>\n",
              "      <td>https://www.sitgesanytime.com/es/blog.htm</td>\n",
              "      <td>Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Ge...</td>\n",
              "      <td>3121</td>\n",
              "      <td>6.21060</td>\n",
              "      <td>-1.283917</td>\n",
              "      <td>1.652930</td>\n",
              "      <td>-0.635692</td>\n",
              "      <td>-0.464640</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/plantilles/turisme/css/font/Intro-Black-Caps....</td>\n",
              "      <td>0.808723</td>\n",
              "      <td>https://www.sitgesanytime.com/es/pl409/blog/id...</td>\n",
              "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
              "      <td>3340</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-1.065819</td>\n",
              "      <td>0.240710</td>\n",
              "      <td>0.104878</td>\n",
              "      <td>1.482033</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/comu/js/jquery-ui-1.13.1/jquery-ui.min.js HTT...</td>\n",
              "      <td>1.747754</td>\n",
              "      <td>https://www.sitgesanytime.com/en/pl355/explore...</td>\n",
              "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
              "      <td>3487</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-0.981935</td>\n",
              "      <td>1.008220</td>\n",
              "      <td>2.145962</td>\n",
              "      <td>-1.582941</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 URL     bytes  \\\n",
              "0  /comu/fancybox/jquery.fancybox.css?v=2.1.7 HTT... -0.597348   \n",
              "1  /nl/pl383/ontdekken/recensies-en-gastheren/men...  0.418239   \n",
              "2  /comu/js/jquery-ui-1.13.1/jquery-ui.min.js HTT...  1.804745   \n",
              "3  /plantilles/turisme/css/font/Intro-Black-Caps....  0.808723   \n",
              "4  /comu/js/jquery-ui-1.13.1/jquery-ui.min.js HTT...  1.747754   \n",
              "\n",
              "                                             referer  \\\n",
              "0  https://www.sitgesanytime.com/es/pl415/blog/ll...   \n",
              "1                                                  -   \n",
              "2          https://www.sitgesanytime.com/es/blog.htm   \n",
              "3  https://www.sitgesanytime.com/es/pl409/blog/id...   \n",
              "4  https://www.sitgesanytime.com/en/pl355/explore...   \n",
              "\n",
              "                                          user-agent  group  elapsed  \\\n",
              "0  Mozilla/5.0 (compatible; AhrefsBot/7.0; +http:...    551  0.00000   \n",
              "1                 PhxBot/0.1 (phxbot@protonmail.com)   1675  1.94591   \n",
              "2  Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Ge...   3121  6.21060   \n",
              "3  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   3340  0.00000   \n",
              "4  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   3487  0.00000   \n",
              "\n",
              "    IP_oct0   IP_oct1   IP_oct2   IP_oct3  ...  minute_cos  petition_-  \\\n",
              "0  0.427313 -0.342599 -0.744068  1.620095  ...         1.0           0   \n",
              "1 -1.820773 -1.110110  2.453028 -0.878825  ...         1.0           0   \n",
              "2 -1.283917  1.652930 -0.635692 -0.464640  ...         1.0           0   \n",
              "3 -1.065819  0.240710  0.104878  1.482033  ...         1.0           0   \n",
              "4 -0.981935  1.008220  2.145962 -1.582941  ...         1.0           0   \n",
              "\n",
              "   petition_GET  petition_HEAD  petition_POST  petition_other  status_1  \\\n",
              "0             1              0              0               0     False   \n",
              "1             1              0              0               0     False   \n",
              "2             1              0              0               0     False   \n",
              "3             1              0              0               0     False   \n",
              "4             1              0              0               0     False   \n",
              "\n",
              "   status_2  status_3  status_4  \n",
              "0         1         0         0  \n",
              "1         0         0         1  \n",
              "2         1         0         0  \n",
              "3         1         0         0  \n",
              "4         1         0         0  \n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Assuming you have a CSV file named 'logs.csv' with columns ['date', 'petition', 'URL', 'status', 'referer', 'user-agent']\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "logs_df = pd.read_csv('../data/sitges_access_clean.csv')\n",
        "#logs_df=logs_df[:2345]\n",
        "logs_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om3ABrBhkUdE",
        "outputId": "ece5ce9b-a9b7-4e5f-85bf-f6d7e8173cd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   status_1\n",
            "0     False\n",
            "1     False\n",
            "2     False\n",
            "3     False\n",
            "4     False\n"
          ]
        }
      ],
      "source": [
        "print(logs_df[[\"status_1\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "tQnGjLqufgNZ",
        "outputId": "7fae9696-e1c9-4fd5-da04-b7b52ff79163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['URL', 'bytes', 'referer', 'user-agent', 'group', 'elapsed', 'IP_oct0',\n",
            "       'IP_oct1', 'IP_oct2', 'IP_oct3', 'month_sin', 'month_cos', 'day_sin',\n",
            "       'day_cos', 'weekday_sin', 'weekday_cos', 'hour_sin', 'hour_cos',\n",
            "       'minute_sin', 'minute_cos', 'petition_-', 'petition_GET',\n",
            "       'petition_HEAD', 'petition_POST', 'petition_other', 'status_1',\n",
            "       'status_2', 'status_3', 'status_4'],\n",
            "      dtype='object')\n",
            "   status_1\n",
            "0         0\n",
            "1         0\n",
            "2         0\n",
            "3         0\n",
            "4         0\n"
          ]
        }
      ],
      "source": [
        "# Divide the data into features (X)\n",
        "print(logs_df.columns)\n",
        "\n",
        "# Convert boolean column to integers\n",
        "logs_df['status_1'] = logs_df['status_1'].astype(int)\n",
        "\n",
        "print(logs_df[[\"status_1\"]].head())\n",
        "\n",
        "#logs_df = logs_df.drop([\"status_1\", \"status_5\"], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 132967/132967 [00:15<00:00, 8721.69it/s]\n",
            "100%|██████████| 132967/132967 [00:15<00:00, 8334.43it/s]\n",
            "100%|██████████| 132967/132967 [00:19<00:00, 6809.33it/s]\n"
          ]
        }
      ],
      "source": [
        "ROOT_DIR = os.path.dirname(os.path.abspath(\"\"))\n",
        "\n",
        "# Load the embeddings\n",
        "embeddings_url = load_embeddings(os.path.join(ROOT_DIR, \"models\", \"embeddings-url.pt\"))\n",
        "# Load the idx2word. This is the vocabulary where each token is associated with an index\n",
        "idx2word_url = load_idx2word(os.path.join(ROOT_DIR, \"models\", \"idx2word-url.json\"))\n",
        "# Load the tokenizer. Just specify the name `charbpe-url` and it will load the tokenizer, which is saved\n",
        "# in the files `charbpe-url-vocab.json` and `charbpe-url-merges.txt`\n",
        "tokenizer_url = load_tokenizer(os.path.join(ROOT_DIR, \"models\"), \"charbpe-url\")\n",
        "\n",
        "url_embeddings = extract_embeddings(\n",
        "\tsequence = logs_df[\"URL\"],\n",
        "\tembeddings = embeddings_url,\n",
        "\tidx2word = idx2word_url,\n",
        "\ttokenizer = tokenizer_url\n",
        ")\n",
        "\n",
        "embeddings_referer = load_embeddings(os.path.join(ROOT_DIR, \"models/embeddings-referer.pt\"))\n",
        "idx2word_referer = load_idx2word(os.path.join(ROOT_DIR, \"models/idx2word-referer.json\"))\n",
        "tokenizer_referer = load_tokenizer(os.path.join(ROOT_DIR, \"models\"), \"charbpe-referer\")\n",
        "embeddings_referer.shape, embeddings_referer.mean(), embeddings_referer.std()\n",
        "\n",
        "# --- this will take additional 3.3 GB of memory---\n",
        "referers_embeddings = extract_embeddings(\n",
        "\tsequence = logs_df[\"referer\"],\n",
        "\tembeddings = embeddings_referer,\n",
        "\tidx2word = idx2word_referer,\n",
        "\ttokenizer = tokenizer_referer\n",
        ")\n",
        "\n",
        "embeddings_useragent = load_embeddings(os.path.join(ROOT_DIR, \"models/embeddings-useragent.pt\"))\n",
        "idx2word_useragent = load_idx2word(os.path.join(ROOT_DIR, \"models/idx2word-useragent.json\"))\n",
        "tokenizer_useragent = load_tokenizer(os.path.join(ROOT_DIR, \"models\"), \"charbpe-useragent\")\n",
        "embeddings_useragent.shape, embeddings_useragent.mean(), embeddings_useragent.std()\n",
        "\n",
        "# --- this will take additional 3.3 GB of memory---\n",
        "useragents_embeddings = extract_embeddings(\n",
        "\tsequence = logs_df[\"user-agent\"],\n",
        "\tembeddings = embeddings_useragent,\n",
        "\tidx2word = idx2word_useragent,\n",
        "\ttokenizer = tokenizer_useragent\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# take the output column\n",
        "#!out = df[\"level\"] I OMIITED THIS\n",
        "# drop the columns that are not needed\n",
        "logs_df = logs_df.drop(columns=[\"URL\", \"referer\", \"user-agent\", \"group\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "urls=[]\n",
        "referers=[]\n",
        "usernames=[]\n",
        "\n",
        "for url, referer, username in zip(url_embeddings, referers_embeddings, useragents_embeddings):\n",
        "    urls.append(url.mean(0).float().numpy())\n",
        "    referers.append(referer.mean(0).float().numpy())\n",
        "    usernames.append(username.mean(0).float().numpy())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ensure that the columns are in the correct order\n",
        "logs_df = logs_df.reindex(columns=['bytes','elapsed', 'IP_oct0', 'IP_oct1', 'IP_oct2', 'IP_oct3', 'month_sin',\n",
        "       'month_cos', 'day_sin', 'day_cos', 'weekday_sin', 'weekday_cos',\n",
        "       'hour_sin', 'hour_cos', 'minute_sin', 'minute_cos', 'petition_-',\n",
        "       'petition_GET', 'petition_HEAD', 'petition_POST', 'petition_other',\n",
        "       'status_1', 'status_2', 'status_3', 'status_4'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['bytes', 'elapsed', 'IP_oct0', 'IP_oct1', 'IP_oct2', 'IP_oct3',\n",
            "       'month_sin', 'month_cos', 'day_sin', 'day_cos', 'weekday_sin',\n",
            "       'weekday_cos', 'hour_sin', 'hour_cos', 'minute_sin', 'minute_cos',\n",
            "       'petition_-', 'petition_GET', 'petition_HEAD', 'petition_POST',\n",
            "       'petition_other', 'status_1', 'status_2', 'status_3', 'status_4'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#Add paddings\n",
        "\n",
        "\"\"\"max_length_url = logs_df['url_embeddings'].apply(len).max() \n",
        "max_length_referer = logs_df['referers_embeddings'].apply(len).max() \n",
        "max_length_useragent = logs_df['useragents_embeddings'].apply(len).max() \n",
        "\n",
        "print(max_length_url, max_length_referer, max_length_useragent)\"\"\" \n",
        "\n",
        "def convert_to_sequence(list_sequence):\n",
        "    # Convert sequences to PyTorch tensors\n",
        "    sequences = [torch.tensor(seq, dtype=torch.float32) for seq in list_sequence]\n",
        "\n",
        "    # Padding sequences\n",
        "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0.0)\n",
        "\n",
        "    # Convert padded sequences back to DataFrame\n",
        "    padded_df = pd.DataFrame(padded_sequences.numpy())\n",
        "\n",
        "    return padded_df\n",
        "\n",
        "def add_sequence_to_dataframe(logs_df, df, column_after):\n",
        "    df1_part1 = logs_df.iloc[:, :logs_df.columns.get_loc(column_after)]\n",
        "    df1_part2 = logs_df.iloc[:, logs_df.columns.get_loc(column_after):]\n",
        "\n",
        "    # Concatenate the parts with df2 in between\n",
        "    logs_df = pd.concat([df1_part1, df, df1_part2], axis=1)\n",
        "    return logs_df\n",
        "\n",
        "\n",
        "\n",
        "sequenced_urls=convert_to_sequence(urls)\n",
        "sequenced_referers=convert_to_sequence(referers)\n",
        "sequenced_usernames=convert_to_sequence(usernames)\n",
        "print(logs_df.columns)\n",
        "# Add the sequences to the original dataframe\n",
        "logs_df=add_sequence_to_dataframe(logs_df, sequenced_urls, \"bytes\")\n",
        "\n",
        "logs_df=add_sequence_to_dataframe(logs_df, sequenced_referers, \"elapsed\")\n",
        "logs_df=add_sequence_to_dataframe(logs_df, sequenced_usernames, \"elapsed\")\n",
        "\n",
        "#Puede que si paso las columnas del dataframe en vez de las listas me deje hacerlo\n",
        "#hAECER pca en la funcion original. O no, nose\n",
        "#! Mirar porque esto va mal!!!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index([               0,                1,                2,                3,\n",
            "                      4,                5,                6,                7,\n",
            "                      8,                9,\n",
            "       ...\n",
            "           'minute_cos',     'petition_-',   'petition_GET',  'petition_HEAD',\n",
            "        'petition_POST', 'petition_other',       'status_1',       'status_2',\n",
            "             'status_3',       'status_4'],\n",
            "      dtype='object', length=115)\n"
          ]
        }
      ],
      "source": [
        "print(logs_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"['url_embeddings', 'bytes', 'referer_embeddings', 'useragent_embeddings', 'elapsed', 'IP_oct0', 'IP_oct1', 'IP_oct2', 'IP_oct3', 'month_sin',\\n       'month_cos', 'day_sin', 'day_cos', 'weekday_sin', 'weekday_cos',\\n       'hour_sin', 'hour_cos', 'minute_sin', 'minute_cos', 'petition_-',\\n       'petition_GET', 'petition_HEAD', 'petition_POST', 'petition_other',\\n       'status_1', 'status_2', 'status_3', 'status_4']\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"['url_embeddings', 'bytes', 'referer_embeddings', 'useragent_embeddings', 'elapsed', 'IP_oct0', 'IP_oct1', 'IP_oct2', 'IP_oct3', 'month_sin',\n",
        "       'month_cos', 'day_sin', 'day_cos', 'weekday_sin', 'weekday_cos',\n",
        "       'hour_sin', 'hour_cos', 'minute_sin', 'minute_cos', 'petition_-',\n",
        "       'petition_GET', 'petition_HEAD', 'petition_POST', 'petition_other',\n",
        "       'status_1', 'status_2', 'status_3', 'status_4']\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>minute_cos</th>\n",
              "      <th>petition_-</th>\n",
              "      <th>petition_GET</th>\n",
              "      <th>petition_HEAD</th>\n",
              "      <th>petition_POST</th>\n",
              "      <th>petition_other</th>\n",
              "      <th>status_1</th>\n",
              "      <th>status_2</th>\n",
              "      <th>status_3</th>\n",
              "      <th>status_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41781</th>\n",
              "      <td>-0.150609</td>\n",
              "      <td>0.367842</td>\n",
              "      <td>0.150074</td>\n",
              "      <td>0.824405</td>\n",
              "      <td>-0.535935</td>\n",
              "      <td>-0.462607</td>\n",
              "      <td>-0.138367</td>\n",
              "      <td>0.442962</td>\n",
              "      <td>-0.613921</td>\n",
              "      <td>-0.783932</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.743145</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89004</th>\n",
              "      <td>-0.281218</td>\n",
              "      <td>0.121318</td>\n",
              "      <td>-0.219708</td>\n",
              "      <td>-0.012162</td>\n",
              "      <td>-0.453734</td>\n",
              "      <td>-0.163140</td>\n",
              "      <td>-0.286839</td>\n",
              "      <td>0.306187</td>\n",
              "      <td>-0.065458</td>\n",
              "      <td>-0.394805</td>\n",
              "      <td>...</td>\n",
              "      <td>0.406737</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16853</th>\n",
              "      <td>-0.113392</td>\n",
              "      <td>-0.449912</td>\n",
              "      <td>0.116516</td>\n",
              "      <td>0.283125</td>\n",
              "      <td>-0.351581</td>\n",
              "      <td>-0.623929</td>\n",
              "      <td>-0.198384</td>\n",
              "      <td>0.210719</td>\n",
              "      <td>-0.426656</td>\n",
              "      <td>-1.319338</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.406737</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43588</th>\n",
              "      <td>-0.204459</td>\n",
              "      <td>-0.452729</td>\n",
              "      <td>-0.250437</td>\n",
              "      <td>0.000545</td>\n",
              "      <td>-0.562697</td>\n",
              "      <td>-0.235387</td>\n",
              "      <td>-0.136437</td>\n",
              "      <td>0.316499</td>\n",
              "      <td>-0.521289</td>\n",
              "      <td>-1.079770</td>\n",
              "      <td>...</td>\n",
              "      <td>0.809017</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38249</th>\n",
              "      <td>-0.185353</td>\n",
              "      <td>0.076407</td>\n",
              "      <td>-0.249526</td>\n",
              "      <td>0.252661</td>\n",
              "      <td>-0.090764</td>\n",
              "      <td>0.047137</td>\n",
              "      <td>-0.446690</td>\n",
              "      <td>0.157244</td>\n",
              "      <td>-0.152935</td>\n",
              "      <td>-0.061733</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 115 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0         1         2         3         4         5         6  \\\n",
              "41781 -0.150609  0.367842  0.150074  0.824405 -0.535935 -0.462607 -0.138367   \n",
              "89004 -0.281218  0.121318 -0.219708 -0.012162 -0.453734 -0.163140 -0.286839   \n",
              "16853 -0.113392 -0.449912  0.116516  0.283125 -0.351581 -0.623929 -0.198384   \n",
              "43588 -0.204459 -0.452729 -0.250437  0.000545 -0.562697 -0.235387 -0.136437   \n",
              "38249 -0.185353  0.076407 -0.249526  0.252661 -0.090764  0.047137 -0.446690   \n",
              "\n",
              "              7         8         9  ...  minute_cos  petition_-  \\\n",
              "41781  0.442962 -0.613921 -0.783932  ...   -0.743145           0   \n",
              "89004  0.306187 -0.065458 -0.394805  ...    0.406737           0   \n",
              "16853  0.210719 -0.426656 -1.319338  ...   -0.406737           0   \n",
              "43588  0.316499 -0.521289 -1.079770  ...    0.809017           0   \n",
              "38249  0.157244 -0.152935 -0.061733  ...    1.000000           0   \n",
              "\n",
              "       petition_GET  petition_HEAD  petition_POST  petition_other  status_1  \\\n",
              "41781             1              0              0               0         0   \n",
              "89004             1              0              0               0         0   \n",
              "16853             1              0              0               0         0   \n",
              "43588             1              0              0               0         0   \n",
              "38249             1              0              0               0         0   \n",
              "\n",
              "       status_2  status_3  status_4  \n",
              "41781         0         1         0  \n",
              "89004         1         0         0  \n",
              "16853         1         0         0  \n",
              "43588         1         0         0  \n",
              "38249         1         0         0  \n",
              "\n",
              "[5 rows x 115 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split the data into train, validation, and test sets\n",
        "X_train, X_test = train_test_split(logs_df, test_size=0.2, random_state=42)\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Lm-4z82nrEpL"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.data = dataframe.values.astype(np.float32) # Assuming dataframe is a pandas DataFrame\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        return torch.tensor(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fCejiapprJDR"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(X_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = CustomDataset(X_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8nswgcS_daf"
      },
      "source": [
        "###Step 3: Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBTChfNT_GgH",
        "outputId": "f5de7756-1db4-4922-d55e-434efaba3528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogAnomalyDetector(\n",
            "  (encoder): LSTM(115, 115, num_layers=3, batch_first=True)\n",
            "  (decoder): LSTM(115, 115, num_layers=3, batch_first=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Define LSTM Autoencoder Model\n",
        "class LogAnomalyDetector(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(LogAnomalyDetector, self).__init__()\n",
        "        self.encoder = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.decoder = nn.LSTM(input_size=hidden_size, hidden_size=input_size, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hidden, cell) = self.encoder(x)\n",
        "        output, _ = self.decoder(hidden)\n",
        "        return output[-1] #Return just the last layer\n",
        "\n",
        "input_size=len(logs_df.columns)\n",
        "hidden_size=input_size #//4\n",
        "num_layers=3\n",
        "\n",
        "# Create an instance of the model\n",
        "model = LogAnomalyDetector(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
        "\n",
        "# Print model summary\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preguntar al Eric si lo ha hecho con embeddings i si es así que como lo ha hecho para que no le de runtime errors\n",
        "# Hacer la mean como solucion parche i justificarlo con lo de que al reves consumia mucha memoria\n",
        "\n",
        "# Probar con el modelo de autoencodeer y el modelo LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6DDCe0ZmoCQ"
      },
      "source": [
        "###Step 4: Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rYl5i8mHmiQu"
      },
      "outputs": [],
      "source": [
        "# Function for training the model\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, inputs in tqdm(enumerate(train_loader, 0)):\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.squeeze(), inputs.squeeze())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vfyP4x8yc2m",
        "outputId": "fe187fbc-21d4-4296-8a64-81b8cc83e2f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\arroc\\AppData\\Local\\Temp\\ipykernel_5036\\2349361552.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  log_tensor = torch.tensor(log_entry).unsqueeze(0)  # Add batch dimension\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reconstructed Log Entry:\n",
            "tensor([ 0.0096,  0.0364, -0.0361, -0.0004,  0.0346, -0.0051, -0.0152, -0.0599,\n",
            "         0.0415, -0.0331,  0.0056, -0.0353, -0.0134,  0.0452,  0.0074,  0.0175,\n",
            "        -0.0513, -0.0137, -0.0013,  0.0411,  0.0479, -0.0068, -0.0094,  0.0371,\n",
            "         0.0021,  0.0138,  0.0380, -0.0547, -0.0096, -0.0098, -0.0045, -0.0909,\n",
            "         0.0285, -0.0152, -0.0065,  0.0448, -0.0102,  0.0363, -0.0212,  0.0094,\n",
            "         0.0056, -0.0161, -0.0268, -0.0375,  0.0694,  0.0027,  0.0038,  0.0444,\n",
            "        -0.0258, -0.0232,  0.0048,  0.0025,  0.0399,  0.0507,  0.0148,  0.0434,\n",
            "         0.0133, -0.0137,  0.0130,  0.0662, -0.0032, -0.0471, -0.0597, -0.0207,\n",
            "        -0.0107,  0.0331, -0.0098,  0.0283,  0.0524,  0.0416,  0.0636, -0.0391,\n",
            "         0.0669, -0.0633, -0.0157, -0.0436, -0.0418,  0.0016, -0.0164, -0.0093,\n",
            "         0.0144, -0.0200,  0.0388, -0.0389, -0.0358,  0.0182, -0.0452, -0.0088,\n",
            "        -0.0526, -0.0052, -0.0530, -0.0477,  0.0152, -0.0361, -0.0246, -0.0294,\n",
            "        -0.0040, -0.0087,  0.0169, -0.0474, -0.0140,  0.0080,  0.0109, -0.0020,\n",
            "        -0.0316, -0.0746,  0.0087, -0.0046, -0.0345,  0.0599,  0.0193,  0.0123,\n",
            "         0.0008, -0.0288, -0.0035], grad_fn=<SelectBackward0>)\n",
            "tensor([[-3.2956e-01,  6.2582e-01, -1.4039e-01,  7.4263e-03, -2.2355e-01,\n",
            "         -2.8405e-01, -1.9601e-01,  1.0811e+00, -6.1892e-01, -4.8640e-01,\n",
            "          4.4215e-01, -4.2926e-01, -5.3347e-01, -1.7376e-01, -3.4131e-01,\n",
            "         -6.2729e-01,  7.8331e-02,  5.0427e-01, -9.7392e-02, -6.0539e-01,\n",
            "         -3.4959e-01,  1.1335e-01,  2.7799e-01, -2.0433e-02, -9.4761e-02,\n",
            "          1.8540e-01, -4.5390e-01, -1.3229e+00,  7.6857e-02,  2.6537e-01,\n",
            "         -1.3017e+00, -7.9994e-01,  2.6285e-01, -1.0593e-01, -1.8445e-01,\n",
            "          2.9073e-01, -3.0522e-01, -8.0855e-02,  7.4846e-02, -1.2691e-01,\n",
            "         -3.6691e-01, -3.3233e-01,  2.6625e-01,  2.5965e-01,  4.9827e-01,\n",
            "         -7.6565e-01,  1.1524e-01,  5.3868e-01,  5.3460e-01,  1.6035e-01,\n",
            "          2.2288e-01,  4.3299e-01,  1.0060e-02, -1.2659e-01, -1.0794e-01,\n",
            "         -1.8173e-01,  4.5640e-01,  2.3284e-01,  1.0308e-01, -5.6948e-01,\n",
            "          4.4920e-01,  2.4586e-01, -2.5880e-01, -7.9608e-01,  4.7688e-01,\n",
            "          3.5047e-01, -1.7132e-01, -2.8173e-01, -6.3842e-02, -4.2032e-01,\n",
            "         -7.0083e-01, -8.4680e-01,  2.2511e-01, -9.1258e-01, -6.1453e-01,\n",
            "         -4.3046e-01, -1.2410e-01,  3.4092e-01,  6.1799e-01,  1.6374e-01,\n",
            "          6.0369e-02, -5.9000e-01,  4.3978e-01, -3.8015e-01,  1.8664e-01,\n",
            "          1.3551e-01,  8.8070e-02, -2.5389e-01,  1.7255e-01,  2.4019e-02,\n",
            "          5.4282e-02,  7.6880e+00,  1.2326e+00,  1.5762e+00, -7.0794e-01,\n",
            "          9.5740e-01,  5.0000e-01,  8.6603e-01, -9.9872e-01, -5.0649e-02,\n",
            "          7.8183e-01,  6.2349e-01,  2.5882e-01,  9.6593e-01,  9.7815e-01,\n",
            "         -2.0791e-01,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00]])\n"
          ]
        }
      ],
      "source": [
        "# Sample log entry\n",
        "log_entry = test_dataset[34]\n",
        "\n",
        "# Convert the log entry to a tensor\n",
        "log_tensor = torch.tensor(log_entry).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Pass the log tensor through the model\n",
        "output_log_tensor = model(log_tensor)\n",
        "\n",
        "# Convert the output tensor back to a numpy array\n",
        "#output_log_entry = output_log_tensor.squeeze().detach().numpy()\n",
        "\n",
        "# Output the reconstructed log entry\n",
        "print(\"Reconstructed Log Entry:\")\n",
        "print(output_log_tensor)\n",
        "print(log_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7oWsSQ8onvr",
        "outputId": "86e8f865-b58a-4fe8-ab10-7ace42263bbb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3325it [00:59, 56.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Loss: 0.126004369205102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2928it [00:52, 56.23it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      8\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m---> 10\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train_model(model, train_loader, criterion, optimizer, num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs)\n",
            "Cell \u001b[1;32mIn[17], line 17\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), inputs\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[0;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     19\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\arroc\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\arroc\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
            "File \u001b[1;32mc:\\Users\\arroc\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    160\u001b[0m         group,\n\u001b[0;32m    161\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    166\u001b[0m         state_steps)\n\u001b[1;32m--> 168\u001b[0m     adam(\n\u001b[0;32m    169\u001b[0m         params_with_grad,\n\u001b[0;32m    170\u001b[0m         grads,\n\u001b[0;32m    171\u001b[0m         exp_avgs,\n\u001b[0;32m    172\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    173\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    174\u001b[0m         state_steps,\n\u001b[0;32m    175\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    176\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    177\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    178\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    179\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    180\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    181\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    182\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    183\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    184\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    185\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    186\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    187\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    188\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    189\u001b[0m     )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "File \u001b[1;32mc:\\Users\\arroc\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 318\u001b[0m func(params,\n\u001b[0;32m    319\u001b[0m      grads,\n\u001b[0;32m    320\u001b[0m      exp_avgs,\n\u001b[0;32m    321\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    322\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    323\u001b[0m      state_steps,\n\u001b[0;32m    324\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    325\u001b[0m      has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    326\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    327\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    328\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m    329\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    330\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    331\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[0;32m    332\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m    333\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[0;32m    334\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[0;32m    335\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
            "File \u001b[1;32mc:\\Users\\arroc\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:393\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    390\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m    394\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Define the criterion (loss function)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adjust learning rate as needed\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 20\n",
        "\n",
        "train_loss = train_model(model, train_loader, criterion, optimizer, num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zsPupZvuTjS"
      },
      "source": [
        "### Step 5: Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7ETMlWmtj7q"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "def test_model(model, test_loader, criterion):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    model.to(device)\n",
        "    test_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.squeeze(), inputs.squeeze())\n",
        "\n",
        "            test_loss += loss.item()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    print(f\"Average Test Loss: {avg_test_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQTccfm-rbWB",
        "outputId": "09bfd6ab-b9b9-42a2-96b3-be1438e80885"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Test Loss: 0.4015493282976632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2, 26])) that is different to the input size (torch.Size([26])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "test_loss = test_model(model, test_loader, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N086256EqqPU"
      },
      "outputs": [],
      "source": [
        "# To get the scoring system, compute the similarity between the output vector and the input vector. (This is just an idea)\n",
        "# An anomaly should give low similarity (This is if the model performs accuratelly the task of autoencode the same vector)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
