{"cells":[{"cell_type":"markdown","metadata":{"id":"StXkBL_k-7KF"},"source":["## Normal Autoencoder"]},{"cell_type":"markdown","metadata":{"id":"mmOe2Y7vrdDN"},"source":["The idea of this approach is that the model has to be able to represent the same log after being transfered into a low dimension. Then, if we train the model with the normal logs (the majority of logs in our dataset) we would have trained the model to represent the normal logs. Therefore, if an anomalous log is presented, the model would work badly, and here is where we can identify the anomaly."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4938,"status":"ok","timestamp":1716373641007,"user":{"displayName":"MARIA DEL MAR GASCON","userId":"07581894320598799750"},"user_tz":-120},"id":"qP7KGPQV_LXg"},"outputs":[],"source":["# imports:\n","\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","\n","\n","from skipgram import *\n","import os\n","\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.nn.functional import cosine_similarity"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716373641007,"user":{"displayName":"MARIA DEL MAR GASCON","userId":"07581894320598799750"},"user_tz":-120},"id":"PH1cQn49faHR"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716373641007,"user":{"displayName":"MARIA DEL MAR GASCON","userId":"07581894320598799750"},"user_tz":-120},"id":"Zcjef9oFmOks"},"outputs":[],"source":["ROOT_DIR = os.path.dirname(os.path.abspath(\"\"))"]},{"cell_type":"markdown","metadata":{"id":"xbGvOnVo_SzQ"},"source":["### Step 1: Data preprocessing"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":36261,"status":"ok","timestamp":1716373677266,"user":{"displayName":"MARIA DEL MAR GASCON","userId":"07581894320598799750"},"user_tz":-120},"id":"HZ09UG7d27HS"},"outputs":[],"source":["# Load the CSV file into a pandas DataFrame\n","logs_df = pd.read_csv('../data/sitges_access_prepared_whole_set_but_last.csv')"]},{"cell_type":"markdown","metadata":{"id":"_ZMz7SqoiBML"},"source":["### Step 2: Dataset\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":256},"executionInfo":{"elapsed":1851,"status":"ok","timestamp":1716373679105,"user":{"displayName":"MARIA DEL MAR GASCON","userId":"07581894320598799750"},"user_tz":-120},"id":"5Pb-CFY8mzm9","outputId":"bae721bd-45a6-48cf-9f9f-68fd9cab9070"},"outputs":[],"source":["# Split the data into train, validation, and test sets\n","X_train, X_temp = train_test_split(logs_df, test_size=0.4, random_state=42)\n","X_val, X_test = train_test_split(X_temp, test_size=0.5, random_state=42)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716373679105,"user":{"displayName":"MARIA DEL MAR GASCON","userId":"07581894320598799750"},"user_tz":-120},"id":"Lm-4z82nrEpL"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, dataframe):\n","        self.data = dataframe.values.astype(np.float32) # Assuming dataframe is a pandas DataFrame\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        sample = self.data[idx]\n","        return torch.tensor(sample)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":575,"status":"ok","timestamp":1716373679677,"user":{"displayName":"MARIA DEL MAR GASCON","userId":"07581894320598799750"},"user_tz":-120},"id":"fCejiapprJDR"},"outputs":[],"source":["train_dataset = CustomDataset(X_train)\n","train_loader = DataLoader(train_dataset, batch_size=1000, shuffle=False)\n","\n","val_dataset = CustomDataset(X_val)\n","val_loader = DataLoader(val_dataset, batch_size=1000, shuffle=False)\n","\n","test_dataset = CustomDataset(X_test)\n","test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"z8nswgcS_daf"},"source":["### Step 3: Model"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716373679677,"user":{"displayName":"MARIA DEL MAR GASCON","userId":"07581894320598799750"},"user_tz":-120},"id":"UBTChfNT_GgH","outputId":"a0361ac4-471f-474c-b8e4-36d786074868"},"outputs":[{"name":"stdout","output_type":"stream","text":["LogAnomalyDetector(\n","  (encoder): Sequential(\n","    (0): Linear(in_features=115, out_features=50, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=50, out_features=20, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=20, out_features=5, bias=True)\n","  )\n","  (decoder): Sequential(\n","    (0): Linear(in_features=5, out_features=20, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=20, out_features=50, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=50, out_features=115, bias=True)\n","  )\n",")\n"]}],"source":["# Define Autoencoder Model\n","class LogAnomalyDetector(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(LogAnomalyDetector, self).__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_size, hidden_size[0]),\n","            nn.ReLU(),\n","            nn.Linear(hidden_size[0], hidden_size[1]),\n","            nn.ReLU(),\n","            nn.Linear(hidden_size[1], hidden_size[2])\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.Linear(hidden_size[2], hidden_size[1]),\n","            nn.ReLU(),\n","            nn.Linear(hidden_size[1], hidden_size[0]),\n","            nn.ReLU(),\n","            nn.Linear(hidden_size[0], input_size)\n","        )\n","\n","    def forward(self, x):\n","        emb = self.encoder(x)\n","        #print(\"Latent space:\", emb)\n","        x = self.decoder(emb)\n","        return x\n","\n","input_size=len(logs_df.columns)\n","hidden_size=[50, 20, 5] \n","\n","# Create an instance of the model\n","model = LogAnomalyDetector(input_size=input_size, hidden_size=hidden_size)\n","model.to(device)\n","\n","# Print model summary\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"T6DDCe0ZmoCQ"},"source":["### Step 4: Training"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716373679677,"user":{"displayName":"MARIA DEL MAR GASCON","userId":"07581894320598799750"},"user_tz":-120},"id":"rYl5i8mHmiQu"},"outputs":[],"source":["# Function for training the model\n","def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n","    model.train()\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        for i, inputs in tqdm(enumerate(train_loader)):\n","            inputs = inputs.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs.squeeze(), inputs.squeeze())\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115049,"status":"ok","timestamp":1716373794723,"user":{"displayName":"MARIA DEL MAR GASCON","userId":"07581894320598799750"},"user_tz":-120},"id":"g7oWsSQ8onvr","outputId":"d66eaaf2-2774-47d1-ae01-f45aaeb84669"},"outputs":[{"name":"stderr","output_type":"stream","text":["534it [00:05, 92.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/20], Loss: 0.08764286366490166\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:06, 86.35it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/20], Loss: 0.049868681297152676\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:05, 104.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/20], Loss: 0.047958169718471805\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:05, 90.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/20], Loss: 0.04538564170511921\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:05, 96.07it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/20], Loss: 0.043962398090500954\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:05, 106.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [6/20], Loss: 0.04331939338884327\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:06, 83.38it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [7/20], Loss: 0.04264342656519529\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:05, 105.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [8/20], Loss: 0.04213571413123652\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:06, 88.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [9/20], Loss: 0.041813429047384956\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:05, 96.86it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [10/20], Loss: 0.04158894991160332\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:05, 105.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [11/20], Loss: 0.04142337720771407\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:06, 85.38it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [12/20], Loss: 0.04129487549544274\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:05, 100.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [13/20], Loss: 0.04118955597867457\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:06, 82.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [14/20], Loss: 0.04109313778495521\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:05, 102.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [15/20], Loss: 0.04100658329489749\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:05, 97.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [16/20], Loss: 0.040924259318450416\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:06, 86.61it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [17/20], Loss: 0.04084469608209106\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:05, 104.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [18/20], Loss: 0.04076496230556947\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:06, 82.06it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch [19/20], Loss: 0.04067158990640765\n"]},{"name":"stderr","output_type":"stream","text":["534it [00:05, 104.61it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [20/20], Loss: 0.040562229740262475\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Define the criterion (loss function)\n","criterion = nn.MSELoss()\n","\n","# Define the optimizer\n","optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adjust learning rate as needed\n","\n","# Train the model\n","num_epochs = 20\n","\n","train_loss = train_model(model, train_loader, criterion, optimizer, num_epochs=num_epochs)"]},{"cell_type":"markdown","metadata":{"id":"4zsPupZvuTjS"},"source":["### Step 5: Test"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1716373794724,"user":{"displayName":"MARIA DEL MAR GASCON","userId":"07581894320598799750"},"user_tz":-120},"id":"i7ETMlWmtj7q"},"outputs":[],"source":["# Test the model\n","def test_model(model, test_loader, criterion):\n","\n","    model.eval()  # Set model to evaluation mode\n","\n","    test_loss = 0.0\n","\n","    with torch.no_grad():\n","        for inputs in test_loader:\n","            inputs = inputs.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs.squeeze(), inputs.squeeze())\n","\n","            test_loss += loss.item()\n","\n","    avg_test_loss = test_loss / len(test_loader)\n","    print(f\"Average Test Loss: {avg_test_loss}\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1571,"status":"ok","timestamp":1716373796292,"user":{"displayName":"MARIA DEL MAR GASCON","userId":"07581894320598799750"},"user_tz":-120},"id":"q80fbCyl6Jk6","outputId":"7a57e8b7-925f-4694-b758-5c57480deac3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Test Loss: 0.04044552532474646\n"]}],"source":["val_loss = test_model(model, val_loader, criterion)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1315,"status":"ok","timestamp":1716373797604,"user":{"displayName":"MARIA DEL MAR GASCON","userId":"07581894320598799750"},"user_tz":-120},"id":"DQTccfm-rbWB","outputId":"8f202971-dbe3-46ab-c883-fa549647b153"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Test Loss: 0.04053921034831679\n"]}],"source":["test_loss = test_model(model, test_loader, criterion)"]},{"cell_type":"markdown","metadata":{},"source":["### Step 6: Upload the model"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716373905592,"user":{"displayName":"MARIA DEL MAR GASCON","userId":"07581894320598799750"},"user_tz":-120},"id":"Y6QxRf9KofN3"},"outputs":[],"source":["# Save the model state dictionary \n","torch.save(model.state_dict(), '../models/normalAutoencoder.pt')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
